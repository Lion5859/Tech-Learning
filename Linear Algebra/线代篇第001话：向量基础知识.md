### 向量与标量

先说物理学上对vector的定义：

> 具有**大小**和**方向**的量 

也就是说vector在描述事物的时候，不仅指明了事物在观测时间的状态，还指明了状态的发展方向，即：趋势 

要搞清楚vector，就必须先说明标量scalars，scalars相比于vector，只描述了事物的状态，并未指明以后的发向

------

这里我们拿**1级的鲁班**来举个栗子，我们假设1级的鲁班，刚出生时的智商是-1，战力是2，那么用scalar描述鲁班，是这个样子的：

![image-20190728155654377](http://ww1.sinaimg.cn/large/006tNc79ly1g5fo3iiqqpj30au0d4q3m.jpg)

而用vector描述鲁班，却是这个样子的：

![image-20190728160329907](http://ww2.sinaimg.cn/large/006tNc79ly1g5fo3j0bdvj30ae0cuaaq.jpg)

看到区别了吗？vector不仅描述了大小，还说明了方向。

这里要说明的是：

- 上面的举例引用了2个参数，所以我在2维空间中进行表述，如果有3个参数(例如：鲁班还有攻击范围)，则应该在3维空间中进行描述……
- 物理学中的向量是可以随意移动的，只要保持大小和方向不变即可(想像一下：1级的鲁班从泉水跑到大龙，位置变了，但是智商和战力却没有变)；而在数学领域，为了表述方便，一般固定以坐标轴原点作为方向的射出点
- 最后，一个向量不会因观测而发生变化；什么意思呢？1级的鲁班在没有外界影响的情况下，你上午看它是智商-1，下午看它还是智商-1……

最后要说的是，在计算机领域对1级鲁班的描述，应该是酱紫滴：
$$
\vec{v}=[-1,2]^T
$$


### 加法运算

什么是加法呢？

举个栗子，七哥过年回家可以选择这样的路线：c=「广州-武汉」，然后再转车w=「武汉-当阳」，而产生的位移量与z=「广州-当阳」相等，也就是说，向量c+w=z

所以，向量相加代表的意义是什么呢？

- 物理学上，向量相加表示向量的线性组合（linear combination），满足平形四边形对角线法则或者三角形法则
- 而在数学上，可以认为是在同一线性空间内的一种映射关系，即：RXR->R;相加后的向量，仍属于同一线性空间

另外向量的加法满足交换律，这个不多描述。

**加法运算逻辑**

这里我们还是拿鲁班来举例，很明显我们知道，「智商」+「战力」是不可行的，因为这俩都不是一个单位，没法搞。但是「鲁班」可以跟「电玩小子」相加吗？必须滴……这是大家都知道的事儿

比如：
$$
1级鲁班：\vec{v}=
 \left[
 \begin{matrix}
   -1\\
   2
  \end{matrix}
  \right]
，
电玩皮肤：\vec{w}= \left[
 \begin{matrix}
   4\\
   2
  \end{matrix}
  \right]
$$
那么穿戴电玩皮肤的1级鲁班的向量组合(Linear Combination)就是：
$$
\vec{v}+\vec{w}=
 \left[
 \begin{matrix}
   -1\\
   2
  \end{matrix}
  \right]
+ \left[
 \begin{matrix}
   4\\
   2
  \end{matrix}
  \right]
  =\left[
 \begin{matrix}
   3\\
   4
  \end{matrix}
  \right]
$$
我们用2维坐标轴表示，应该就是这样的：

![image-20190728161740080](http://ww1.sinaimg.cn/large/006tNc79ly1g5fo3huyejj30la0i6q5c.jpg)

正好是平等四边形的对角线

**几种基础加法运算**

- 向量v放大以倍以后与放大d倍的向量w的线性组合

$$
c\vec{v}+d\vec{w}\tag{1}
$$

- 0向量(注意：它仍然是向量，其元素都是0而已，可以理解为0维空间，宇宙奇点，哈哈～)

$$
0\vec{v}+0\vec{w}=0\tag{2}
$$

- 向量压缩(将向量w降维至0维，然后与v进行线性组合，组合后的向量与v在同一方向）

$$
c\vec{v}+0\vec{w}=c\vec{v}\tag{3}
$$

------

最后，上述例子主要是基于2维空间进行表述，同样的做法可以推广至3维，甚至N维空间……这个就需要自行脑补了



### 乘法运算

乘法的逻辑，暂时想不明白，大概说明下计算过程


$$
\vec{v}=
 \left[
 \begin{matrix}
   -1&4\\
   2&2
  \end{matrix}
  \right]
，
\vec{w}= \left[
	\begin{matrix}
	1\\
	2
	\end{matrix}
	\right]
$$
两者相乘的结果就是：
$$
\vec{v} \cdot \vec{w}=
 \left[
 \begin{matrix}
   -1&4\\
   2&2
  \end{matrix}
  \right]
\cdot \left[
	\begin{matrix}
	1\\
	2
	\end{matrix}
	\right]
  =\left[
 \begin{matrix}
   -1*1+4*2\\
   2*1+2*2
  \end{matrix}
  \right]
  =\left[
 \begin{matrix}
   7\\
   6
  \end{matrix}
  \right]
$$
大致意思就是，$\vec{v}$中的两个列向量，分别经1、2倍放大之后，再进行线性组合，算是能力组合吧……期待大神补充说明



### 点积运算

两个向量的点积(dot product或者inner product)为：$\vec{v}\cdot\vec{w}=\sum{v_i \cdot w_i}$

举例来说，假设有向量:$\vec{v}=[4,2]^T$及$\vec{w}=[-1,2]^T$，则其点积为：4*(-1)+2\*2=0

点积在几何上，反映的就是两个向量的夹角$\theta$，而且：

- 大于0则表示两个向量的夹角小于90$^\circ$
- 小于0则表示夹角大于90$^\circ$
- 等于0则表示夹角等于90$^\circ$，也就是垂直关系

![image-20190728162340494](http://ww3.sinaimg.cn/large/006tNc79ly1g5fo3jh4jxj30le0aiwft.jpg)



**长度**

长度比较简单，$||v||=\sqrt{v_1^2+v_2^2+\cdots+v_n^2}$

直观的几何意义，就是这个箭头的长度

**单位向量**

这是一个很重要的概念，很多场景下为了方便计算，都会将向量单位化为长度为1，然后再进行各种计算。

其数学表达式为：$u=v/||v||$

------

最后补上两条重要的不等式作为收尾。

Schwarz不等式：$|v\cdot w|\leq||v||\cdot||w||$

三角形不等式：$||v+w||\leq||v||+||w||$
